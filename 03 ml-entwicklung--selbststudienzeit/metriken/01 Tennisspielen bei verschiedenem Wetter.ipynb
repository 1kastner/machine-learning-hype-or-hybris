{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tennisspielen bei verschiedenem Wetter\n",
    "\n",
    "Dies ist der gleiche Datensatz wie bei der Einführung.\n",
    "Diesmal ist der Schwerpunkt auf den verschiedenen Metriken, mit denen die Güte bewertet werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No', 'No', 'Yes'], dtype=object)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn.tree\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "\n",
    "df = pd.read_csv(\"../../01 einfuehrende-beispiele/tennis.tsv\", sep=\" \\t\", engine=\"python\")\n",
    "one_hot_encoded = pd.get_dummies(df[[\"Outlook\", \"Temperature\", \"Humidity\", \"Wind\"]])\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(one_hot_encoded, df[\"Play Tennis?\"])\n",
    "dt = sklearn.tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun visualisieren wir einmal als Tabelle kurz, wie häufig wir falsch lagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted actual\n",
       "9        Yes    Yes\n",
       "11        No    Yes\n",
       "2         No    Yes\n",
       "7        Yes     No"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation = pd.DataFrame(data={\n",
    "    \"predicted\": y_pred,\n",
    "    \"actual\": y_test\n",
    "})\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metriken\n",
    "\n",
    "Die Metriken helfen dabei, in Zahlen die Diskrepanz zwischen der Vorhersage und dem tatsächlichen Wert in Zahlen zu fassen.\n",
    "Hier nun ein paar Beispiele, was man messen kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metriken\n",
      "- ConfusionMatrixDisplay\n",
      "- PrecisionRecallDisplay\n",
      "- RocCurveDisplay\n",
      "- accuracy_score\n",
      "- adjusted_mutual_info_score\n",
      "- adjusted_rand_score\n",
      "- auc\n",
      "- average_precision_score\n",
      "- balanced_accuracy_score\n",
      "- brier_score_loss\n",
      "- calinski_harabasz_score\n",
      "- calinski_harabaz_score\n",
      "- check_scoring\n",
      "- classification_report\n",
      "- cluster\n",
      "- cohen_kappa_score\n",
      "- completeness_score\n",
      "- confusion_matrix\n",
      "- consensus_score\n",
      "- coverage_error\n",
      "- davies_bouldin_score\n",
      "- dcg_score\n",
      "- euclidean_distances\n",
      "- explained_variance_score\n",
      "- f1_score\n",
      "- fbeta_score\n",
      "- fowlkes_mallows_score\n",
      "- get_scorer\n",
      "- hamming_loss\n",
      "- hinge_loss\n",
      "- homogeneity_completeness_v_measure\n",
      "- homogeneity_score\n",
      "- jaccard_score\n",
      "- jaccard_similarity_score\n",
      "- label_ranking_average_precision_score\n",
      "- label_ranking_loss\n",
      "- log_loss\n",
      "- make_scorer\n",
      "- matthews_corrcoef\n",
      "- max_error\n",
      "- mean_absolute_error\n",
      "- mean_gamma_deviance\n",
      "- mean_poisson_deviance\n",
      "- mean_squared_error\n",
      "- mean_squared_log_error\n",
      "- mean_tweedie_deviance\n",
      "- median_absolute_error\n",
      "- multilabel_confusion_matrix\n",
      "- mutual_info_score\n",
      "- nan_euclidean_distances\n",
      "- ndcg_score\n",
      "- normalized_mutual_info_score\n",
      "- pairwise\n",
      "- pairwise_distances\n",
      "- pairwise_distances_argmin\n",
      "- pairwise_distances_argmin_min\n",
      "- pairwise_distances_chunked\n",
      "- pairwise_kernels\n",
      "- plot_confusion_matrix\n",
      "- plot_precision_recall_curve\n",
      "- plot_roc_curve\n",
      "- precision_recall_curve\n",
      "- precision_recall_fscore_support\n",
      "- precision_score\n",
      "- r2_score\n",
      "- recall_score\n",
      "- roc_auc_score\n",
      "- roc_curve\n",
      "- silhouette_samples\n",
      "- silhouette_score\n",
      "- v_measure_score\n",
      "- zero_one_loss\n"
     ]
    }
   ],
   "source": [
    "print(\"Metriken\")\n",
    "for entry in dir(sklearn.metrics):\n",
    "    if entry.startswith(\"_\") or entry == entry.upper():\n",
    "        continue\n",
    "    print(\"-\", entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted actual\n",
       "9        Yes    Yes\n",
       "11        No    Yes\n",
       "2         No    Yes\n",
       "7        Yes     No"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision \t [0.5 0. ]\n",
      "Recall \t\t [0.33333333 0.        ]\n",
      "F-Score \t [0.4 0. ]\n",
      "Support \t [3 1]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = sklearn.metrics.precision_recall_fscore_support(y_test.values, y_pred,\n",
    "                                                                                     labels=[\"Yes\", \"No\"])\n",
    "\n",
    "print(\"Precision \\t\", precision)\n",
    "print(\"Recall \\t\\t\", recall)\n",
    "print(\"F-Score \\t\", fscore)\n",
    "print(\"Support \\t\", support)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aufgabe 1)**\n",
    "\n",
    "Berechnen Sie selbständig diese vier Werte.\n",
    "Hinweise gibt es z. B. im \n",
    "[Wikipedia-Artikel zum binären Klassifikator](https://de.wikipedia.org/wiki/Beurteilung_eines_bin%C3%A4ren_Klassifikators)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antwort: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Lizenzvertrag\" style=\"border-width:0; display:inline\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a> &nbsp;&nbsp;&nbsp;&nbsp;Dieses Werk von Marvin Kastner ist lizenziert unter einer <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Namensnennung 4.0 International Lizenz</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-hype-or-hybris] *",
   "language": "python",
   "name": "conda-env-ml-hype-or-hybris-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
