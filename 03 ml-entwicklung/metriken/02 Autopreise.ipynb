{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autopreise\n",
    "\n",
    "Die Daten stammen von https://data.world/data-society/used-cars-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection\n",
    "import sklearn.linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../01 einfuehrende-beispiele/autos.csv\", encoding=\"ISO-8859-1\")\n",
    "df_kleinwagen = df[df[\"vehicleType\"] == \"kleinwagen\"]\n",
    "df_kleinwagen = df_kleinwagen[~(df_kleinwagen[\"price\"] > 20000)]\n",
    "df_ford_fiesta = df_kleinwagen[df_kleinwagen[\"name\"] == \"Ford_Fiesta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(df_ford_fiesta[\n",
    "    [\"kilometer\", \"yearOfRegistration\"]], df_ford_fiesta[\"price\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = sklearn.linear_model.LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "y_pred = lm.predict(X_test)\n",
    "\n",
    "pd.DataFrame(data={\n",
    "    \"y_test\": y_test.values, \n",
    "    \"y_pred\": y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test - y_pred).plot.hist()\n",
    "plt.xlabel(\"Preisdifferenz (€)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metriken\n",
    "\n",
    "Für den Vergleich von zwei Zahlen bieten sich andere Metriken als bei dem Vergleich von zwei Kategorien an.\n",
    "Hier kann die Differenz der zwei Preise aufschlussreich sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Metriken\")\n",
    "for entry in dir(sklearn.metrics):\n",
    "    if entry.startswith(\"_\") or entry == entry.upper():\n",
    "        continue\n",
    "    print(\"-\", entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relativ einfach zu interpretieren ist der Mean Average Error:\n",
    "\n",
    "$MAE = \\frac{1}{n} \\sum | \\hat{y_i} - y_i |$\n",
    "\n",
    "Das ist der Durchschnitt der Beträge der Differenzen.\n",
    "Deswegen ist die Angabe auch wieder in der ursprünglichen Einheit (hier also €)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.mean_absolute_error(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ebenfalls gut interpretierbar ist der RMSE:\n",
    "\n",
    "$RMSE = \\sqrt{ \\frac{1}{n} \\sum ( \\hat{y_i} - y_i ) ^2 }$\n",
    "\n",
    "Auch diese Größe ist in der ursprünglichen Einheit (hier also €)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sklearn.metrics.mean_squared_error(y_pred, y_test.values))**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine ganz andere Metrik ist $R^2$.\n",
    "Bei $R^2 = 1$ funktioniert das Modell perfekt (oh, da müssen wir kritisch sein, es gibt immer kleine Fehler)!\n",
    "Bei $R^2 = 0$ ist das Modell genauso gut, wie wenn man einfach den Durchschnitt berechnet hätte.\n",
    "Das heißt, die Mühe war eigentlich umsonst.\n",
    "Bei negativen $R^2$-Werten heißt es, dass das Modell sogar schlechter als der Durchschnitt ist.\n",
    "Dann sollte es erst recht nicht eingesetzt werden!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich der Vorhersage mit dem Durchschnitt\n",
    "\n",
    "sklearn.metrics.r2_score(y_pred, [y_test.values.mean() for _ in range(len(y_pred))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich\n",
    "\n",
    "sklearn.metrics.r2_score(y_pred, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.r2_score(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das heißt, das Modell ist besser als der Durchschnitt, aber es gibt noch Luft nach oben.\n",
    "\n",
    "Vielleicht kann man bei der Linearen Regression mehr Attribute verwenden?\n",
    "Vielleicht gibt es andere Lernalgorithmen (Neuronale Netze etc.), die hier besser funktionieren?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-hype-or-hybris] *",
   "language": "python",
   "name": "conda-env-ml-hype-or-hybris-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
