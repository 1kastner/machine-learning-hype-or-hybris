{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# P-Hacking\n",
    "\n",
    "Das Konzept P-Hacking bedeutet, dass man absichtlich so lange die Auswertung der eigenen Daten verändert, bis genau die Werte herauskommen, die zur eigenen Hypothese passen.\n",
    "Dieses Verhalten ist ein Problem für alle Bereiche:\n",
    "In der Wissenschaft werden unter Umständen falsche Hypothesen (fälschlicherweise) empirisch untermauert.\n",
    "In der Praxis bedeutet es, dass ggf. defekte Modelle in den Betrieb aufgenommen werden.\n",
    "Sobald sich jemand auf das falsche Modell verlässt, kann dies zu ernsthaften Schäden an Menschen oder Umwelt führen.\n",
    "Ebenso sind finanzielle Schäden nicht ausgeschlossen.\n",
    "Weiterführende Infos gibt es z. B. auf\n",
    "[Wikipedia](https://de.wikipedia.org/wiki/P-Hacking)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Zunächst wird wieder der Zufallsgenerator fixiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Es werden wieder zufällige Attribute erzeugt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.random.randint(0, 10, size=(50, 26)), columns=list('ABCDEFGHIJKLMNOPQRSTUVWXYZ'))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Wie stark sind die Korrelationen ausgeprägt?\n",
    "Dies wird nun visualisiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(19, 15))\n",
    "df_corr = df.corr()\n",
    "plt.matshow(df_corr, fignum=fig.number, cmap='RdBu', vmin=-1, vmax=1)\n",
    "plt.xticks(range(df.shape[1]), df.columns)\n",
    "plt.yticks(range(df.shape[1]), df.columns)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Die Korrelationsmatrix ist symmetrisch, wenn A und B korrelieren, korrelieren auch B und A.#\n",
    "Deswegen blenden wir nur die eine Hälfte der Matrix aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "upper_right_matrix = df_corr.where(np.triu(np.ones(df_corr.shape), k=1).astype(bool)) \n",
    "\n",
    "fig = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(upper_right_matrix, fignum=fig.number, cmap='RdBu', vmin=-1, vmax=1)\n",
    "plt.xticks(range(upper_right_matrix.shape[1]), upper_right_matrix.columns)\n",
    "plt.yticks(range(upper_right_matrix.shape[1]), upper_right_matrix.columns)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Eine reduzierte Darstellung lässt sich wie folgt finden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "stacked_df = upper_right_matrix.stack().reset_index()\n",
    "stacked_df.columns = [\"attribute_A\", \"attribute_B\", \"r\"]\n",
    "stacked_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature-Engineering falsch gemacht\n",
    "\n",
    "Nun werden wir so lange neue Features erstellen, bis wir (mindestens) eines finden, dass mit einem Attribut korreliert.\n",
    "Hierhinter steht keinerlei Theorie, es sind reine Zufallsdaten.\n",
    "Dafür werden die Attribute addiert und multipliziert.\n",
    "Andere Operatoren wie Division und Subtraktion wären natürlich genauso möglich.\n",
    "Darüber hinaus könnte man noch viel mehr Funktionen verwenden, wie Sinus, Logarithmus etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Hier werden die Additionen zweier Attribute gespeichert\n",
    "additions = []\n",
    "\n",
    "# Hier werden die Multiplikationen zweier Attribute gespeichert\n",
    "multiplications = []\n",
    "\n",
    "for index, (column_A, column_B, r) in stacked_df.iterrows():\n",
    "\n",
    "    addition = df[column_A] + df[column_B]\n",
    "    addition.name = f\"{column_A} + {column_B}\"\n",
    "    additions.append(addition)\n",
    "\n",
    "    multiplication = df[column_A] * df[column_B]\n",
    "    multiplication.name = f\"{column_A} * {column_B}\"\n",
    "    multiplications.append(multiplication)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Diese kreierten Attribute fügen wir nun dem DataFrame hinzu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df = df.assign(**{series.name : series for series in additions})\n",
    "df = df.assign(**{series.name : series for series in multiplications})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(19, 15))\n",
    "plt.matshow(df.corr(), fignum=fig.number, cmap='RdBu', vmin=-1, vmax=1)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_corr = df.corr()\n",
    "upper_right_matrix = df_corr.where(np.triu(np.ones(df_corr.shape), k=1).astype(bool)) \n",
    "df_high_corr = upper_right_matrix[(df_corr > .5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Es sind sehr viele Attribute geworden und dies lässt sich nun auch schwer visuell inspizieren.\n",
    "Deswegen untersuchen wir diese Korrelationskoeffizienten nun weiter.\n",
    "Dafür werden diese zunächst in eine Liste überführt.\n",
    "Dadurch geht die Information verloren, wie genau die Zeilen heißen, die korrelieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cor_values = df_corr.values.flatten()\n",
    "pd.DataFrame(cor_values, columns=[\"Korrelationskoeffizient\"]).plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Sehr viele Korrelationen sind nur sehr schwach ausgeprägt.\n",
    "Deswegen kann man diese im Histogramm besser erkennen als die stärkeren Korrelationen.\n",
    "Um die stärker ausgeprägten Korrelationen besser sehen zu können, entfernen wir den mittleren Teil.\n",
    "Außerdem ist weniger von Interesse, ob eine Korrelation positiv oder negativ ist.\n",
    "Die hier eingesetzte Funktion `abs()` nimmt den absoluten Betrag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(abs(cor_values[((cor_values < -.5) | (cor_values > .5))])).plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Es sieht so aus, als ob die Suche erfolgreich war.\n",
    "Bei 0,9 gibt es mehrere Einträge.\n",
    "Hier zoomen wir weiter heran."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(abs(cor_values[((cor_values < -.9) | (cor_values > .9))])).plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es sind auffällig viele hohe Korrelationen dabei.\n",
    "Dies wird nun weiter inspiziert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inspiziere die Korrelationen der Features\n",
    "\n",
    "Zunächst filtern wir die Korrelationen aus der vorherigen Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "correlating = []\n",
    "\n",
    "for attribute_A in df_high_corr.columns:\n",
    "    for attribute_B, correlation_coefficient in df_high_corr[attribute_A].loc[\n",
    "        ~pd.isnull(df_high_corr[attribute_A])\n",
    "    ].iteritems():\n",
    "        correlation_coefficient = df_high_corr[attribute_A].loc[attribute_B]\n",
    "        correlating.append((attribute_A, attribute_B, correlation_coefficient))\n",
    "\n",
    "df_corr_summary = pd.DataFrame(correlating, columns = [\"Attribut A\", \"Attribut B\", \"r\"])\n",
    "df_corr_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Nun werden alle trivialen Fälle herausgefiltert.\n",
    "Dazu gehören solche, wo in beiden Termen das gleiche Attribut vorkommt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "interesting_indices = []\n",
    "\n",
    "for index, attribute_A, attribute_B, r in df_corr_summary.itertuples():\n",
    "\n",
    "    if attribute_A in attribute_B or attribute_B in attribute_A:\n",
    "        # einfacher Fall: A ~ A*A oder A ~ A+A\n",
    "        continue\n",
    "\n",
    "    variables_A = [v for v in attribute_A if v not in (\" \", \"*\", \"+\")]\n",
    "    variables_B = [v for v in attribute_B if v not in (\" \", \"*\", \"+\")]\n",
    "\n",
    "    if set(variables_A).intersection(variables_B):\n",
    "        # einfacher Fall: ein Operand kommt auf beiden Seiten vor\n",
    "        continue\n",
    "\n",
    "    interesting_indices.append(index)\n",
    "\n",
    "df_corr_summary.loc[interesting_indices].plot.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "df_corr_summary.loc[interesting_indices].sort_values(by=\"r\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Solche zufällig entstehenden Korrelationen treten dadurch auf, dass wir lang genug verschiedene Terme durchprobiert haben.\n",
    "Diese Korrelationen würden mit einer anwachsenden Datenmenge (mehr Beobachtungen je Attribut) höchstwahrscheinlich verschwinden.\n",
    "Häufig kann die Aufteilung in Trainings- und Testset helfen, diese Situation zu erkennen.\n",
    "Allerdings gibt es immer eine gewisse Wahrscheinlichkeit, dass zufälligerweise das Testset so ausgewählt worden ist, dass es keinen Hinweis gibt, dass etwas im Argen liegt.\n",
    "\n",
    "Ein Lernalgorithmus könnte auf Basis von solchen wahllos kreierten Features Korrelationen finden, die diese zu falsche Vorhersagen verleitet.\n",
    "Deswegen ist es wichtig, dass Lernverfahren für die Größe des vorliegenden Datensatzes nie zu komplex werden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-hype-or-hybris] *",
   "language": "python",
   "name": "conda-env-ml-hype-or-hybris-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
