{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifiziere Verkehrsschilder\n",
    "\n",
    "In diesem Jupyter Notebook geht es um die Erkennung von Verkehrszeichen.\n",
    "Der dafür verwendete Datensatz ist der German Traffic Sign Recognition Benchmark, kurz GTSRB.\n",
    "Sämtliche Informationen rund um den Datensatz sind [online](http://benchmark.ini.rub.de/?section=gtsrb&subsection=news) einsehbar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path\n",
    "import imageio\n",
    "import skimage.transform\n",
    "import skimage.feature\n",
    "import skimage.color\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Außerdem gibt es noch ein selbstgeschriebenes Modul, welches quasi neben den Jupyter Notebooks liegt.\n",
    "Hier sind Funktionen ausgelagert worden, die das Notebook unübersichtlich machen würden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtsrb_image_database_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das obige Modul kann die Bilddatenbank so laden, dass alle Metadaten vorliegen.\n",
    "Nur so kann man später die Bilder für die Erkennung einsetzen.\n",
    "Allerdings müssen die Bilder auf der Festplatte liegen.\n",
    "Der Schritt des Herunterladens muss händisch vorgenommen werden.\n",
    "\n",
    "1. Für das Herunterladen der Daten für die Übung klicken Sie bitte [hier](https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/GTSRB_Final_Training_Images.zip). Bitte laden Sie die ZIP-Datei herunter.\n",
    "2. Entpacken Sie das ZIP-Archiv in den gleichen Ordner wie dieses Jupyter Notebook.\n",
    "\n",
    "Falls man sich auf einem PC mit Linux als Betriebssystem befindet, kann man auch das Skript `download_traffic_signs.sh` ausführen, welches sich im gleichen Ordner wie dieses Jupyter Notebook befindet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Laden der Meta-Informationen\n",
    "--------------------------------\n",
    "\n",
    "Zunächst laden wir die Meta-Informationen, d. h. welche Bilder es gibt, wie groß diese sind, wo diese auf der Festplatte liegen sowie in welchem Ausschnitt des Bildes sich das Verkehrszeichen befindet.\n",
    "Legen Sie das Verzeichnis `GTSRB` in das gleiche Verzeichnis wie das Notebook.\n",
    "Falls das Kopieren zu viel Zeit benötigt, passen Sie `path_to_directory` so an, dass der Pfad auf den entpackten Ordner mit den Verkehrsschildern zeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starte im gleichen Ordner (relativer Pfad)\n",
    "path_to_directory = \"./GTSRB_Final_Training_Images/GTSRB/Final_Training/Images\"  \n",
    "\n",
    "# alternativ: gebe absoluten Pfad an\n",
    "#path_to_directory = \"C:/asdfasdf/\"\n",
    "\n",
    "df = gtsrb_image_database_loader.load_traffic_sign_database(path_to_directory)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laden der Bilder\n",
    "-------------------\n",
    "\n",
    "Hier werden alle Bilder geladen, zurechtgeschnitten und auf eine einheitliche Größe gebracht.\n",
    "Farbinformationen können vernachlässigt werden.\n",
    "Die Bilder werden dann dem DataFrame als neue Spalte hinzugefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for row in gtsrb_image_database_loader.log_progress(df.itertuples(), size=len(df)):\n",
    "    color_image = imageio.imread(row.path_to_image).astype(int, copy=False)\n",
    "    gray_image = skimage.color.rgb2gray(color_image)\n",
    "    cropped_image = gray_image[row.Roi_Y1:row.Roi_Y2, row.Roi_X1:row.Roi_X2]\n",
    "    resized_image = skimage.transform.resize(cropped_image, [40, 40], mode=\"constant\")\n",
    "    images.append(resized_image)\n",
    "df = df.assign(image=images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein Verkehrsschild sieht nun so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image = df.iloc[0].image\n",
    "plt.imshow(sample_image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extrahieren eines Features\n",
    "-------------------------------\n",
    "\n",
    "Mithilfe von Histograms of Gradients (HOGs) können Gegenstände gut automatisiert klassifiziert werden.\n",
    "Diese werden z. B. im Artikel [\"Histograms of Oriented Gradients for Human Detection\" von N. Dalal und B. Triggs](https://hal.inria.fr/docs/00/54/85/12/PDF/hog_cvpr2005.pdf) gut beschrieben.\n",
    "Die HOGs des oben gezeigte Beispielbild werden im Folgenden angezeigt.\n",
    "\n",
    "Eine einfache Möglichkeit, Bilder in HOGs umzuwandeln, wird von [scikit-image](http://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.hog) bereitgestellt und im Folgenden verwendet.\n",
    "Die Parameter `orientations`, `pixels_per_cell`, `cells_per_block` und `block_norm` beziehen sich auf den HOG-Algorithmus und können variiert werden.\n",
    "\n",
    "Zunächst wird für das obige Verkehrszeichen gezeigt, wie die HOG-Repräsentation aussieht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_img = skimage.feature.hog(\n",
    "    sample_image,\n",
    "    transform_sqrt=True,\n",
    "    orientations=8,\n",
    "    pixels_per_cell=(6, 6),\n",
    "    cells_per_block=(3, 3),\n",
    "    feature_vector=True,\n",
    "    block_norm=\"L2-Hys\",\n",
    "    visualize=True\n",
    ")[1]\n",
    "plt.imshow(hog_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun werden die HOG-Werte für sämtliche Bilder berechnet.\n",
    "Das Ergebnis wird als eine neue Spalte dem DataFrame hinzugefügt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_features = []\n",
    "for row in gtsrb_image_database_loader.log_progress(df.itertuples(), size=len(df)):\n",
    "    hog_feature = skimage.feature.hog(\n",
    "        row.image,\n",
    "        transform_sqrt=True,\n",
    "        orientations=8,\n",
    "        pixels_per_cell=(6, 6),\n",
    "        cells_per_block=(3, 3),\n",
    "        feature_vector=True,\n",
    "        block_norm=\"L2-Hys\",\n",
    "        visualize=False\n",
    "    )\n",
    "    hog_features.append(hog_feature)\n",
    "df = df.assign(hog_feature=hog_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun sind die Daten soweit vorbereitet, dass der Zusammenhang zwischen dem Bild und dem Verkehrszeichen durch eine geeignete Methode des ML hergestellt werden kann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aufteilen in Trainings- und Validierungs-Sets\n",
    "------------------------------------------------------\n",
    "\n",
    "Es werden 67 % als Trainings- und 33 % als Test-Daten verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df[\"hog_feature\"].values\n",
    "targets = df[\"ClassId\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, targets, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noch eine Kleinigkeit:\n",
    "Die HOGs liegen als Arrays von Arrays vor, der Lernalgorithmus benötigt aber ein einzelnes langes Array.\n",
    "Dafür müssen die Arrays aneinander gehängt werden.\n",
    "Dies kann einfach durch[`np.stack`](https://docs.scipy.org/doc/numpy-1.14.0/reference/generated/numpy.stack.html) vorgenommen werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.stack(X_train)\n",
    "X_test = np.stack(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training und Evaluierung mit einem Klassifizierer\n",
    "--------------------------------------------------------\n",
    "\n",
    "Als Klassifizierungs-Algorithmus wird ein Random Forest (RF) eingesetzt.\n",
    "Der Random Forest ist ein Ensemble von mehreren Entscheidungsbäumen.\n",
    "Im Folgenden wird eine [Implementierung von scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) eingesetzt.\n",
    "\n",
    "Für die Bewertung der Ergebnisse können nun verschiedene Aspekte betrachtet werden.\n",
    "Die Accuracy ist ein einfaches Maß, um den Anteil der richtig bestimmten Klassen zu quantifizieren.\n",
    "Die Confusion Matrix ermöglicht es, zu sehen, welche Klassen miteinander verwechselt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=10,\n",
    "    max_depth=7,\n",
    "    n_jobs=-1,\n",
    "    max_features=\"auto\",\n",
    "    class_weight=None\n",
    ")\n",
    "random_forest.fit(X_train, y_train)\n",
    "predicted = random_forest.predict(X_test)\n",
    "confusion_matrix = metrics.confusion_matrix(\n",
    "    y_test,\n",
    "    predicted,\n",
    "    labels=range(43)\n",
    ")\n",
    "score = random_forest.score(X_test, y_test)\n",
    "print(\"Accuracy: {score} %\".format(score=score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine schöne Möglichkeit, eine Confusion Matrix zu visualisieren, ist, diese als Bild zu plotten.\n",
    "Der folgende Code ist der [Dokumentation von scikit-learn](http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html) entnommen und angepasst worden.\n",
    "Die Verkehrsschilder (als Liste in der Variablen `classes`) werden durch die Zahlen 0 bis 42 repräsentiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df.ClassId.unique()\n",
    "\n",
    "normalized_confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "img = ax.imshow(normalized_confusion_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    \n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45, label='Tatsächliche Klassen-ID')\n",
    "plt.yticks(tick_marks, classes, label='Vom Algorithmus angenommene Klassen-ID')\n",
    "\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar(img, shrink=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mit interaktiven Widgets die Datenbank durchsuchen\n",
    "\n",
    "Hier kann man nun sehen, welche Verkehrszeichen besonders häufig miteinander verwechselt werden.\n",
    "Aber welche werden denn nun verwechselt?\n",
    "Dafür gibt es nun ein kleines Such-Tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample_for_class_id(_id):\n",
    "    sample_image_for_class_id = df[df.ClassId == _id].iloc[0]\n",
    "    plt.title(\"Class ID: \" + str(int(_id)))\n",
    "    plt.imshow(sample_image_for_class_id.image, cmap='gray')\n",
    "    return sample_image_for_class_id\n",
    "\n",
    "plot_sample_for_class_id(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "input_field = widgets.FloatText()\n",
    "\n",
    "def on_change(x):\n",
    "    clear_output(wait=True)\n",
    "    display(input_field)\n",
    "    information = plot_sample_for_class_id(x[\"new\"])\n",
    "    display(information)\n",
    "    \n",
    "input_field.observe(on_change, names='value')\n",
    "\n",
    "input_field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Datensatz ist bereits häufiger in [wissenschaftlichen Veröffentlichungen](http://benchmark.ini.rub.de/?section=gtsrb&subsection=results) referenziert worden.\n",
    "Besonders zu empfehlen ist der Artikel \"Man vs. computer: Benchmarking machine learning algorithms for traffic sign recognition\" von J. Stallkamp, M. Schlipsing, J. Salmena und C. Igel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Lizenzvertrag\" style=\"border-width:0; display:inline\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a> &nbsp;&nbsp;&nbsp;&nbsp;Dieses Werk von Marvin Kastner ist lizenziert unter einer <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Namensnennung 4.0 International Lizenz</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
